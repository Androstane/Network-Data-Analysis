{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 5\n",
    "Name:Yushu Liu\n",
    "\n",
    "Wustlkey:yushu.liu\n",
    "\n",
    "Partner Name:\n",
    "\n",
    "Partner Wustlkey:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes and Submission Instructions:  \n",
    "* **Libraries**: You may use available NetworkX functions. \n",
    "* **Comments**: Comment your code to receive maximum credit.\n",
    "* **Number of Cells**: Do not change the number of (code or markdown) cells in this notebook.\n",
    "* **What to submit**: Only submit the hw3_problem3.ipynb - nothing else. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Community Detection - Empirical Study Code (30%)\n",
    "\n",
    "In this problem we will compare the different community detection algorithms studied in class for multiple real world social networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Datset Statistics (code ungraded)\n",
    "Add a table summaraizing the statistics to your written pdf submission. \n",
    "\n",
    "__[optional] Your Program Below:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import itertools\n",
    "from networkx.algorithms.community.centrality import girvan_newman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 [Implementation] Betweenness-Based Clustering (10%)\n",
    "\n",
    "Write a function that computes betweenness-based clustering (using the Girvan-Newman algorithm) taking the number of clusters k as an input. Comment your code to receive maximum credit.\n",
    "\n",
    "__Your Program Below:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Code adapt from networkx networkx.algorithms.community.centrality.girvan_newman\n",
    "def betweenneess_clustering(G,k):\n",
    "    #Use the girvan newman algorithm to compute clustering of G at all level\n",
    "    comp = girvan_newman(G)\n",
    "    #print out the desired number (k) of community at clustering \n",
    "    limited = itertools.takewhile(lambda c: len(c) <= k, comp)\n",
    "    for communities in limited:\n",
    "        community_list = (list(sorted(c) for c in communities)) \n",
    "    print(modularity(G, community_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 [Implementation] Modularity Maximization  (10%)\n",
    "Write a function that computes modularity-based clustering (modularity maximization) taking the number of clusters k as an input. Comment your code to receive maximum credit.\n",
    "\n",
    "__Your Code Below:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from networkx.algorithms.community.quality import modularity\n",
    "def find_leading_vector(A):\n",
    "    #A = nx.to_numpy_matrix(G)\n",
    "    # nodes degree vector\n",
    "    k = np.sum(A,axis=0)\n",
    "    # two times total number of edges\n",
    "    twom = np.sum(k)\n",
    "    # modularity matrix\n",
    "    B = A - np.outer(k,k)/twom\n",
    "    x,v = eigh(B)\n",
    "    vector = v.T\n",
    "    leading_vector = vector[-1].tolist()\n",
    "    return leading_vector\n",
    "\n",
    "#perform Modularity Maximization with desired cluster number k\n",
    "#check q after each split, stop if q < qmax    \n",
    "def Mod_Max(G,k):\n",
    "    n_cluster = 1\n",
    "    A = nx.to_numpy_matrix(G)\n",
    "    community_dict = {u: 0 for u in G}\n",
    "    q = 0\n",
    "    while (n_cluster < k):\n",
    "        qmax = -9999;\n",
    "        for i in range(0, n_cluster):\n",
    "            L = []\n",
    "            for key, value in community_dict.items():\n",
    "                if i == value:\n",
    "                    L.append(key)\n",
    "            new_dict = community_dict;\n",
    "            #find subgraph after each partition and recompute\n",
    "            A_sub = nx.to_numpy_matrix(G.subgraph(L))\n",
    "            leading_vector = find_leading_vector(A_sub)\n",
    "            for i in range (0, len(leading_vector)): \n",
    "                if leading_vector[i] < 0:\n",
    "                    new_dict[L[i]] = n_cluster\n",
    "            #Keep track of current node list\n",
    "            Node_List = []\n",
    "            for j in range(0, n_cluster+1):\n",
    "                L = []\n",
    "                for key, value in new_dict.items():\n",
    "                    if j == value:\n",
    "                        L.append(key)\n",
    "\n",
    "                Node_List.append(L)\n",
    "            #compute modularit score at current iteration\n",
    "            qi = modularity(G, Node_List)\n",
    "            #comment out to force algoritm running to desired nubmer of cluster for karate dataset\n",
    "            #if qi > qmax:\n",
    "                #qmax = qi\n",
    "                #max_dict = new_dict\n",
    "        #if qmax<q:\n",
    "            #break\n",
    "        community_dict = max_dict\n",
    "        q = qmax\n",
    "        print(q)\n",
    "        n_cluster = n_cluster + 1        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 [Implementation] Spectral Clustering  (10%)\n",
    "Write a function that computes spectral clustering (using the graph Laplacian) taking the number of clusters k as an input. Comment your code to receive maximum credit.\n",
    "\n",
    "__Your Code Below:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from networkx.algorithms.community.quality import modularity\n",
    "#find the sparset cut from adjacency matrix of graph \n",
    "def find_sparsest_cut(A):\n",
    "    k = np.sum(A,axis=0)\n",
    "    L = -A\n",
    "    for i in range(0, len(k)):\n",
    "        L[i][i]=k[i]\n",
    "    x,v = eigh(L)\n",
    "    vector = v.T\n",
    "    sparsest_cut = vector[2-1].tolist()\n",
    "    return sparsest_cut\n",
    "\n",
    "#perform Spectral cluster with desired cluster number k\n",
    "#check q after each split, stop if q < qmax\n",
    "def Spec_cluster(G,k):\n",
    "    #keep track of current number of clusters with n_cluster\n",
    "    n_cluster = 1\n",
    "    A = nx.to_numpy_matrix(G)\n",
    "    community_dict = {u: 0 for u in G}\n",
    "    q = 0\n",
    "    while (n_cluster < k):\n",
    "        qmax = -9999;\n",
    "        for i in range(0, n_cluster):\n",
    "            L = []\n",
    "            for key, value in community_dict.items():\n",
    "                if i == value:\n",
    "                    L.append(key)\n",
    "            new_dict = community_dict;\n",
    "            #find subgraph after each partition and recompute\n",
    "            A_sub = nx.to_numpy_matrix(G.subgraph(L))\n",
    "            sparsest_cut = find_sparsest_cut(A_sub)\n",
    "            for i in range (0, len(sparsest_cut)): \n",
    "                if sparsest_cut[i] < 0:\n",
    "                    new_dict[L[i]] = n_cluster\n",
    "            #Keep track of current node list\n",
    "            Node_List = []\n",
    "            for j in range(0, n_cluster+1):\n",
    "                L = []\n",
    "                for key, value in new_dict.items():\n",
    "                    if j == value:\n",
    "                        L.append(key)\n",
    "\n",
    "                Node_List.append(L)\n",
    "            #compute modularit score at current iteration\n",
    "            qi = modularity(G, Node_List)\n",
    "            if qi > qmax:\n",
    "                qmax = qi\n",
    "                max_dict = new_dict\n",
    "        #comment out to force algoritm running to desired nubmer of cluster for karate dataset\n",
    "        #if qmax<q:\n",
    "            #break\n",
    "        community_dict = max_dict\n",
    "        q = qmax\n",
    "        print(q)\n",
    "        n_cluster = n_cluster + 1        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Quantitative Comparison (code ungraded)\n",
    "Run all three methods on the three datasets (KARATE, DOLPHINS, JAZZ) for k = 2,3,4,5 and report the following for all methods and datasets:\n",
    "• modulaity score for all clusterings\n",
    "• runtime of the algorithm (HINT: re-execute your computation 5-10 times and take the mode runtime to get a better estimate as runtimes might vary for different runs).\n",
    "\n",
    "Add a table summarizing the result to your written submission. Answer the question in your written submission: According to your findings, which algorithm performs the best (wr.t. both efficiency and quality)?\n",
    "\n",
    "\n",
    "__[optional] Your Program Below:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Qualitative Comparison (no code submission required)\n",
    "Justify the quality of your results by visualizing the clusters. Use Gephi (https://gephi.org), an open source graph visualization and analysis tool. Try differnt layouts and experiment with node and edge coloring, sizes, etc.! Add your visualization and a careful description on what your visualization shows to your written submission.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
